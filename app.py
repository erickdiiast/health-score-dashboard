"""
Health Score Dashboard - Backend API
Processa dados de jogadores e calcula mÃ©tricas de saÃºde/engajamento
ParÃ¢metros dinÃ¢micos calculados a partir dos dados carregados
"""

from fastapi import FastAPI, UploadFile, File, HTTPException, Query
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, FileResponse, StreamingResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import io
import json
import sqlite3
import os
from typing import List, Dict, Any, Optional
import uvicorn
import sys
import warnings
warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl')

# Detecta ambiente
def get_base_dir():
    """Retorna o diretÃ³rio base do aplicativo"""
    if getattr(sys, 'frozen', False):
        # Rodando como executÃ¡vel PyInstaller
        # sys.executable Ã© o caminho do .exe
        return os.path.dirname(sys.executable)
    elif 'PYTHONANYWHERE_DOMAIN' in os.environ:
        # PythonAnywhere
        return os.path.dirname(os.path.abspath(__file__))
    else:
        # Desenvolvimento local
        return os.path.dirname(os.path.abspath(__file__))

BASE_DIR = get_base_dir()
IS_PYTHONANYWHERE = 'PYTHONANYWHERE_DOMAIN' in os.environ
IS_FROZEN = getattr(sys, 'frozen', False)

app = FastAPI(title="Health Score Dashboard", version="2.8.0")

# ConfiguraÃ§Ã£o do banco de dados SQLite
DB_PATH = os.path.join(BASE_DIR, "historico.db")

print(f"[INFO] Base dir: {BASE_DIR}")
print(f"[INFO] DB path: {DB_PATH}")
print(f"[INFO] Frozen: {IS_FROZEN}")
print(f"[INFO] PythonAnywhere: {IS_PYTHONANYWHERE}")

def init_db():
    """Inicializa o banco de dados SQLite para histÃ³rico"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    # Tabela de snapshots do dia
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS snapshots (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            data TEXT NOT NULL,
            data_timestamp TEXT NOT NULL,
            total_jogadores INTEGER,
            percentual_ativos REAL,
            media_score_geral REAL,
            media_score_login REAL,
            media_score_engajamento REAL,
            media_score_compras REAL,
            cluster_elite INTEGER,
            cluster_muito_bom INTEGER,
            cluster_estavel INTEGER,
            cluster_baixo INTEGER,
            cluster_risco_receita INTEGER,
            cluster_risco_engajamento INTEGER,
            filtro_regiao TEXT DEFAULT 'all',
            filtro_vip TEXT DEFAULT 'all'
        )
    ''')
    
    # Tabela de clusters por dia (para detalhamento)
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS clusters_dia (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            snapshot_id INTEGER,
            cluster_nome TEXT,
            quantidade INTEGER,
            percentual REAL,
            score_compras_medio REAL,
            score_engajamento_medio REAL,
            FOREIGN KEY (snapshot_id) REFERENCES snapshots (id)
        )
    ''')
    
    # NOVA TABELA: Acompanhamento individual de jogadores
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS player_snapshots (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            player_id TEXT NOT NULL,
            data TEXT NOT NULL,
            data_timestamp TEXT NOT NULL,
            
            -- Scores calculados
            score_geral REAL,
            score_engajamento REAL,
            score_compras REAL,
            score_login REAL,
            
            -- MÃ©tricas brutas de compras
            qtd_compras_7d INTEGER,
            ticket_medio_7d REAL,
            
            -- MÃ©tricas brutas de engajamento
            qtd_torneios_3d INTEGER,
            qtd_maratonas_3d INTEGER,
            qtd_missoes_3d INTEGER,
            qtd_promos_3d INTEGER,
            qtd_logins_3d INTEGER,
            
            -- ClassificaÃ§Ã£o
            categoria TEXT,
            nivel_vip INTEGER,
            regiao TEXT,
            
            -- Campanhas (para anÃ¡lise de eficÃ¡cia)
            campanha_nome TEXT,
            
            -- Ãndices para consultas rÃ¡pidas
            FOREIGN KEY (player_id) REFERENCES players(player_id) ON DELETE CASCADE
        )
    ''')
    
    # Ãndices para performance
    cursor.execute('''
        CREATE INDEX IF NOT EXISTS idx_player_snapshots_player_date 
        ON player_snapshots(player_id, data)
    ''')
    
    cursor.execute('''
        CREATE INDEX IF NOT EXISTS idx_player_snapshots_date 
        ON player_snapshots(data)
    ''')
    
    cursor.execute('''
        CREATE INDEX IF NOT EXISTS idx_player_snapshots_categoria 
        ON player_snapshots(categoria)
    ''')
    
    # Ãndice UNIQUE para evitar duplicatas (um registro por jogador por dia)
    # Primeiro, remove duplicatas existentes (mantÃ©m o registro com maior id = mais recente)
    try:
        cursor.execute('''
            DELETE FROM player_snapshots 
            WHERE id NOT IN (
                SELECT MAX(id) 
                FROM player_snapshots 
                GROUP BY player_id, data
            )
        ''')
        deleted = cursor.rowcount
        if deleted > 0:
            print(f"[INFO] {deleted} registros duplicados removidos de player_snapshots")
    except Exception as e:
        print(f"[WARN] Erro ao remover duplicatas: {e}")
    
    cursor.execute('''
        CREATE UNIQUE INDEX IF NOT EXISTS idx_player_snapshots_unique 
        ON player_snapshots(player_id, data)
    ''')
    
    conn.commit()
    conn.close()

# Inicializa o banco na startup
init_db()

# CORS para permitir requisiÃ§Ãµes do frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Configurar caminhos de arquivos estÃ¡ticos
STATIC_DIR = os.path.join(BASE_DIR, "static")
TEMPLATES_DIR = os.path.join(BASE_DIR, "templates")

# Se estiver em _internal (PyInstaller), usa esse caminho
if IS_FROZEN and not os.path.exists(STATIC_DIR):
    STATIC_DIR = os.path.join(BASE_DIR, "_internal", "static")
    TEMPLATES_DIR = os.path.join(BASE_DIR, "_internal", "templates")

print(f"[INFO] Static dir: {STATIC_DIR}")
print(f"[INFO] Templates dir: {TEMPLATES_DIR}")

# Servir arquivos estÃ¡ticos
app.mount("/static", StaticFiles(directory=STATIC_DIR), name="static")

# Cache temporÃ¡rio dos dados processados
cached_data = {}

# ========== PARÃ‚METROS PADRÃƒO (fallback) ==========
DEFAULT_PARAMS = {
    'torneios_por_dia': 40,
    'maratonas_por_dia': 11,
    'missoes_por_dia': 3,
    'promos_por_dia': 9,
    'janela_logins_dias': 3,
}

# ========== MAPEAMENTO NÃVEIS VIP ==========
VIP_MAPPING = {
    1: {'nome': 'Ametista', 'cor': '#9B59B6', 'icone': 'ğŸ’'},
    2: {'nome': 'TopÃ¡zio', 'cor': '#F39C12', 'icone': 'ğŸ’ '},
    3: {'nome': 'Esmeralda', 'cor': '#27AE60', 'icone': 'ğŸ”·'},
    4: {'nome': 'Opala', 'cor': '#E74C3C', 'icone': 'ğŸ”¶'},
    5: {'nome': 'Berilo', 'cor': '#3498DB', 'icone': 'ğŸ‘‘'},
}

def get_vip_info(nivel: int) -> Dict:
    """Retorna informaÃ§Ãµes do nÃ­vel VIP"""
    return VIP_MAPPING.get(nivel, {'nome': 'Desconhecido', 'cor': '#95A5A6', 'icone': 'â“'})


def media_sem_zeros(serie) -> float:
    """
    Calcula mÃ©dia desconsiderando zeros e valores nulos.
    Apenas participantes ativos entram no cÃ¡lculo.
    """
    if serie is None or len(serie) == 0:
        return 0
    
    # Filtra apenas valores > 0 (participantes ativos)
    valores_validos = serie[serie > 0]
    
    if len(valores_validos) == 0:
        return 0
    
    return valores_validos.mean()


def get_regiao(translation: str) -> str:
    """
    Identifica a regiÃ£o do jogador baseado na traduÃ§Ã£o.
    Retorna: 'es' (Espanhol), 'br' (Brasil), 'int' (Internacional)
    """
    if pd.isna(translation):
        return 'int'
    
    translation = str(translation).lower().strip()
    
    # Espanhol
    if translation in ['es_ar', 'es_es', 'es_la', 'es_mx', 'es']:
        return 'es'
    
    # Brasil
    if translation in ['pt_br', 'pt-br', 'pt']:
        return 'br'
    
    # Internacional (todos os outros)
    return 'int'


def get_regiao_nome(regiao: str) -> str:
    """Retorna o nome amigÃ¡vel da regiÃ£o"""
    nomes = {
        'es': 'Espanhol',
        'br': 'Brasil',
        'int': 'Internacional',
        'all': 'Todos'
    }
    return nomes.get(regiao, 'Desconhecido')


class HealthScoreCalculator:
    """Calcula scores de saÃºde para jogadores com parÃ¢metros dinÃ¢micos"""
    
    def __init__(self, params: Dict[str, float] = None):
        self.params = params or self._calcular_params_padrao()
    
    @staticmethod
    def calcular_params_dinamicos(df: pd.DataFrame) -> Dict[str, float]:
        """
        Calcula parÃ¢metros dinÃ¢micos baseados nas mÃ©dias do dataset:
        - MÃ©dia de torneios_3d / 3
        - MÃ©dia de maratonas_3d / 3
        - MÃ©dia de missÃµes_3d / 3
        - MÃ©dia de promoÃ§Ãµes_3d / 3
        """
        params = {
            'janela_logins_dias': 3,
            'fonte': 'dinamico'  # Marca que sÃ£o parÃ¢metros calculados
        }
        
        # Normaliza nomes de colunas
        df_cols = df.columns.str.lower().str.strip()
        
        # Mapeia colunas possÃ­veis
        col_mapping = {
            'torneios': ['qtd_torneios_3d', 'torneios_3d', 'qtd_torneios'],
            'maratonas': ['qtd_maratonas_3d', 'maratonas_3d', 'qtd_maratonas'],
            'missoes': ['qtd_missoes_3d', 'missoes_3d', 'qtd_missoes', 'qtd_missÃµes_3d'],
            'promos': ['qtd_promos_3d', 'promos_3d', 'qtd_promos'],
        }
        
        def encontrar_coluna(possiveis):
            for col in possiveis:
                if col in df_cols:
                    return col
            return None
        
        # Calcula mÃ©dias e converte para "por dia"
        # FÃ³rmula: MÃ‰DIA(qtd_xxx_3d) / 3 = mÃ©dia por dia
        
        # Torneios - mÃ©dia apenas de quem participou (ignora zeros)
        col_torneios = encontrar_coluna(col_mapping['torneios'])
        if col_torneios:
            media_torneios_3d = media_sem_zeros(df[col_torneios])
            params['torneios_por_dia'] = media_torneios_3d / 3
            params['media_torneios_3d'] = media_torneios_3d
            # Desvio padrÃ£o e mediana tambÃ©m ignorando zeros
            valores_torneios = df[col_torneios][df[col_torneios] > 0]
            params['desvpad_torneios_3d'] = valores_torneios.std() if len(valores_torneios) > 0 else 0
            params['mediana_torneios_3d'] = valores_torneios.median() if len(valores_torneios) > 0 else 0
        else:
            params['torneios_por_dia'] = DEFAULT_PARAMS['torneios_por_dia']
        
        # Maratonas - mÃ©dia apenas de quem participou (ignora zeros)
        col_maratonas = encontrar_coluna(col_mapping['maratonas'])
        if col_maratonas:
            media_maratonas_3d = media_sem_zeros(df[col_maratonas])
            params['maratonas_por_dia'] = media_maratonas_3d / 3
            params['media_maratonas_3d'] = media_maratonas_3d
            valores_maratonas = df[col_maratonas][df[col_maratonas] > 0]
            params['desvpad_maratonas_3d'] = valores_maratonas.std() if len(valores_maratonas) > 0 else 0
            params['mediana_maratonas_3d'] = valores_maratonas.median() if len(valores_maratonas) > 0 else 0
        else:
            params['maratonas_por_dia'] = DEFAULT_PARAMS['maratonas_por_dia']
        
        # MissÃµes - mÃ©dia apenas de quem participou (ignora zeros)
        col_missoes = encontrar_coluna(col_mapping['missoes'])
        if col_missoes:
            media_missoes_3d = media_sem_zeros(df[col_missoes])
            params['missoes_por_dia'] = media_missoes_3d / 3
            params['media_missoes_3d'] = media_missoes_3d
            valores_missoes = df[col_missoes][df[col_missoes] > 0]
            params['desvpad_missoes_3d'] = valores_missoes.std() if len(valores_missoes) > 0 else 0
            params['mediana_missoes_3d'] = valores_missoes.median() if len(valores_missoes) > 0 else 0
        else:
            params['missoes_por_dia'] = DEFAULT_PARAMS['missoes_por_dia']
        
        # PromoÃ§Ãµes - mÃ©dia apenas de quem participou (ignora zeros)
        col_promos = encontrar_coluna(col_mapping['promos'])
        if col_promos:
            media_promos_3d = media_sem_zeros(df[col_promos])
            params['promos_por_dia'] = media_promos_3d / 3
            params['media_promos_3d'] = media_promos_3d
            valores_promos = df[col_promos][df[col_promos] > 0]
            params['desvpad_promos_3d'] = valores_promos.std() if len(valores_promos) > 0 else 0
            params['mediana_promos_3d'] = valores_promos.median() if len(valores_promos) > 0 else 0
        else:
            params['promos_por_dia'] = DEFAULT_PARAMS['promos_por_dia']
        
        # Logins - mÃ©dia apenas de quem logou (ignora zeros)
        col_logins = encontrar_coluna(['qtd_logins_3d', 'logins_3d'])
        if col_logins:
            params['media_logins_3d'] = media_sem_zeros(df[col_logins])
            valores_logins = df[col_logins][df[col_logins] > 0]
            params['desvpad_logins_3d'] = valores_logins.std() if len(valores_logins) > 0 else 0
            params['mediana_logins_3d'] = valores_logins.median() if len(valores_logins) > 0 else 0
        
        # Calcula os fatores de conversÃ£o
        # FÃ³rmula: 100 / (mÃ©dia_3d * 1.5) - jogador acima da mÃ©dia ganha mais pontos
        # Multiplicamos por 1.5 para que quem estÃ¡ na mÃ©dia ganhe ~67 pontos
        # e quem estÃ¡ 50% acima da mÃ©dia ganhe 100 pontos
        
        for metrica in ['torneios', 'maratonas', 'missoes', 'promos']:
            media_3d = params.get(f'media_{metrica}_3d', 0)
            if media_3d > 0:
                # Fator: 100 pontos = 1.5x a mÃ©dia (desempenho acima da mÃ©dia)
                params[f'{metrica}_factor'] = 100 / (media_3d * 1.5)
            else:
                params[f'{metrica}_factor'] = 1.0
        
        # Fator para logins (benchmark: mÃ©dia dos jogadores)
        media_logins = params.get('media_logins_3d', 3)
        if media_logins > 0:
            params['logins_factor'] = 100 / (media_logins * 1.5)
        else:
            params['logins_factor'] = 33.33
        
        return params
    
    @staticmethod
    def _calcular_params_padrao() -> Dict[str, float]:
        """Retorna parÃ¢metros padrÃ£o do Dashboard_2"""
        params = DEFAULT_PARAMS.copy()
        params['fonte'] = 'padrao'
        
        # Calcula fatores baseados nos valores padrÃ£o
        params['torneios_factor'] = 100 / (params['torneios_por_dia'] * 3)
        params['maratonas_factor'] = 100 / (params['maratonas_por_dia'] * 3)
        params['missoes_factor'] = 100 / (params['missoes_por_dia'] * 3)
        params['promos_factor'] = 100 / (params['promos_por_dia'] * 3)
        params['logins_factor'] = 100 / 3
        
        return params
    
    def calcular_score_login(self, df: pd.DataFrame) -> pd.Series:
        """
        Calcula score de login baseado em:
        - Dias desde Ãºltimo login (decaimento exponencial)
        - Quantidade de logins na janela de 3 dias
        """
        hoje = datetime.now()
        scores = []
        
        for _, row in df.iterrows():
            pontuacoes = []
            
            # RecÃªncia do Ãºltimo login
            if 'lastlogin' in df.columns and pd.notna(row.get('lastlogin')):
                try:
                    last_login = pd.to_datetime(row['lastlogin'])
                    dias_desde_login = (hoje - last_login).days
                    login_score = 100 * np.exp(-max(0, dias_desde_login) / 7)
                    pontuacoes.append(login_score)
                except:
                    pass
            
            # FrequÃªncia de logins na janela de 3 dias
            if 'qtd_logins_3d' in df.columns:
                qtd = row.get('qtd_logins_3d', 0)
                if pd.notna(qtd):
                    freq_score = min(qtd * self.params['logins_factor'], 100)
                    pontuacoes.append(freq_score)
            
            if pontuacoes:
                scores.append(np.mean(pontuacoes))
            else:
                scores.append(50)
        
        return pd.Series(scores)
    
    def calcular_score_engajamento(self, df: pd.DataFrame) -> pd.Series:
        """
        Calcula score de engajamento usando Z-Score baseado em desvio padrÃ£o:
        - Torneios: Z-score da quantidade de torneios
        - Maratonas: Z-score da quantidade de maratonas
        - MissÃµes: Z-score da quantidade de missÃµes
        - PromoÃ§Ãµes: Z-score da quantidade de promoÃ§Ãµes
        - Logins: Z-score da quantidade de logins
        
        Z-Score = (valor - mÃ©dia) / desvio_padrÃ£o
        Score final = 50 + (z_score * 25)  # MÃ©dia = 50, cada desvio = 25 pontos
        """
        scores = []
        
        # Calcula estatÃ­sticas para cada atividade (com fillna(0) para zeros)
        atividades = {
            'torneios': {'col': 'qtd_torneios_3d', 'peso': 2.0},
            'maratonas': {'col': 'qtd_maratonas_3d', 'peso': 2.5},
            'missoes': {'col': 'qtd_missoes_3d', 'peso': 1.5},
            'promos': {'col': 'qtd_promos_3d', 'peso': 1.0},
            'logins': {'col': 'qtd_logins_3d', 'peso': 1.0}
        }
        
        # Calcula mÃ©dia e desvio padrÃ£o para cada atividade
        stats = {}
        for key, config in atividades.items():
            col = config['col']
            if col in df.columns:
                valores = df[col].fillna(0)
                media = valores.mean()
                std = valores.std() if len(valores) > 1 else 1
                if std == 0:
                    std = 1  # Evita divisÃ£o por zero
                stats[key] = {'media': media, 'std': std, 'peso': config['peso']}
        
        for _, row in df.iterrows():
            atividades_scores = []
            atividades_pesos = []
            
            # Calcula Z-Score para cada atividade
            for key, stat in stats.items():
                col = atividades[key]['col']
                valor = row.get(col, 0) or 0
                
                # Calcula Z-Score
                z_score = (valor - stat['media']) / stat['std']
                # Converte Z-Score para escala 0-100 (mÃ©dia = 50, desvio = 25)
                atividade_score = 50 + (z_score * 25)
                # Limita entre 0 e 100
                atividade_score = max(0, min(100, atividade_score))
                
                atividades_scores.append(atividade_score * stat['peso'])
                atividades_pesos.append(stat['peso'])
            
            if atividades_scores:
                # MÃ©dia ponderada das atividades
                score_final = sum(atividades_scores) / sum(atividades_pesos)
                scores.append(score_final)
            else:
                scores.append(40)  # Score padrÃ£o se nÃ£o houver dados
        
        return pd.Series(scores)
    
    def calcular_score_compras(self, df: pd.DataFrame) -> pd.Series:
        """
        Calcula score de compras usando Z-Score baseado em desvio padrÃ£o:
        - Quantidade (40%): Z-score da quantidade de compras
        - Ticket MÃ©dio (35%): Z-score do ticket mÃ©dio
        - RecÃªncia (25%): Quanto mais recente, melhor
        
        Z-Score = (valor - mÃ©dia) / desvio_padrÃ£o
        Score final = 50 + (z_score * 25)  # MÃ©dia = 50, cada desvio = 25 pontos
        """
        scores = []
        hoje = datetime.now()
        
        # Calcula estatÃ­sticas para quantidade (ignorando zeros)
        if 'qtd_compras_7d' in df.columns:
            valores_qtd = df['qtd_compras_7d'].fillna(0)
            media_qtd = valores_qtd.mean()
            std_qtd = valores_qtd.std() if len(valores_qtd) > 1 else 1
            if std_qtd == 0:
                std_qtd = 1  # Evita divisÃ£o por zero
        else:
            media_qtd = 2
            std_qtd = 1
        
        # Calcula estatÃ­sticas para ticket (ignorando zeros)
        if 'ticket_medio_7d' in df.columns:
            valores_ticket = df['ticket_medio_7d'].fillna(0)
            media_ticket = valores_ticket.mean()
            std_ticket = valores_ticket.std() if len(valores_ticket) > 1 else 1
            if std_ticket == 0:
                std_ticket = 1
        else:
            media_ticket = 50
            std_ticket = 10
        
        for _, row in df.iterrows():  
            pontuacoes = []
            pesos = []
            
            # 1. Quantidade de compras (40% de peso) - Z-Score
            if 'qtd_compras_7d' in df.columns:
                qtd = row.get('qtd_compras_7d', 0) or 0
                # Calcula Z-Score
                z_score_qtd = (qtd - media_qtd) / std_qtd
                # Converte Z-Score para escala 0-100 (mÃ©dia = 50, desvio = 25)
                qtd_score = 50 + (z_score_qtd * 25)
                # Limita entre 0 e 100
                qtd_score = max(0, min(100, qtd_score))
                pontuacoes.append(qtd_score * 0.40)
                pesos.append(0.40)
            
            # 2. Ticket mÃ©dio (35% de peso) - Z-Score
            if 'ticket_medio_7d' in df.columns:
                ticket = row.get('ticket_medio_7d', 0) or 0
                # Calcula Z-Score
                z_score_ticket = (ticket - media_ticket) / std_ticket
                # Converte Z-Score para escala 0-100
                ticket_score = 50 + (z_score_ticket * 25)
                # Limita entre 0 e 100
                ticket_score = max(0, min(100, ticket_score))
                pontuacoes.append(ticket_score * 0.35)
                pesos.append(0.35)
            
            # 3. RecÃªncia da Ãºltima compra (25% de peso)
            if 'ultima_compra' in df.columns and pd.notna(row.get('ultima_compra')):
                try:
                    ultima = pd.to_datetime(row['ultima_compra'])
                    dias_ultima = (hoje - ultima).days
                    # Decaimento: 100% no dia 0, 50% aos 21 dias, 25% aos 42 dias
                    recencia_score = 100 * np.exp(-max(0, dias_ultima) / 30)
                    pontuacoes.append(recencia_score * 0.25)
                    pesos.append(0.25)
                except:
                    pass
            
            if pontuacoes:
                # MÃ©dia ponderada
                score_final = sum(pontuacoes) / sum(pesos) if sum(pesos) > 0 else 30
                scores.append(score_final)
            else:
                scores.append(0)  # Sem dados de compra = 0
        
        return pd.Series(scores)
    
    def calcular_score_geral(self, row: pd.Series) -> float:
        """Calcula score geral ponderado"""
        engajamento = row.get('score_engajamento', 50)
        compras = row.get('score_compras', 30)
        
        # PonderaÃ§Ã£o: Engajamento 30%, Compras 70%
        return engajamento * 0.3 + compras * 0.7
    
    def categorizar_jogador(self, row: pd.Series) -> str:
        """
        Categoriza jogador com granularidade para aÃ§Ãµes de CRM:
        
        Hierarquia de categorizaÃ§Ã£o:
        1. Primeiro verifica oportunidades (alto engajamento + baixas compras)
        2. Depois categoriza por score geral
        3. Por fim, identifica tipo de risco
        """
        score_geral = row.get('score_geral', 50)
        score_compras = row.get('score_compras', 0)
        score_engajamento = row.get('score_engajamento', 0)
        nivel_vip = row.get('nivel_vip', 1)
        
        # OPORTUNIDADES: Alto engajamento mas compras baixas
        # Estes sÃ£o prioritÃ¡rios para CRM pois tÃªm potencial
        if score_engajamento >= 60 and score_compras < 40:
            if nivel_vip >= 3:
                return "ğŸ’° Oportunidade VIP"
            else:
                return "ğŸ’° Oportunidade"
        
        # POTENCIAL: Bom engajamento, compras mÃ©dias
        if score_engajamento >= 40 and score_compras >= 30 and score_compras < 50:
            return "ğŸ¯ Potencial"
        
        # CategorizaÃ§Ã£o por score geral (mais granular)
        if score_geral >= 90:
            return "â­ Elite"
        elif score_geral >= 80:
            return "ğŸ† VIP Ativo"
        elif score_geral >= 65:
            return "ğŸ“ˆ Bom"
        elif score_geral >= 50:
            return "ğŸ“Š EstÃ¡vel"
        elif score_geral >= 40:
            return "âš ï¸ AtenÃ§Ã£o"
        elif score_geral >= 25:
            # Risco moderado - identificar causa
            if score_compras < 25 and score_engajamento < 35:
                return "ğŸš¨ Risco Alto"
            elif score_compras < score_engajamento:
                return "ğŸš¨ Risco: Queda Receita"
            else:
                return "ğŸš¨ Risco: Queda Engajamento"
        else:
            # Score < 25 = CrÃ­tico
            if score_compras < 15 and score_engajamento < 20:
                return "ğŸ’ Churn Iminente"
            elif score_compras < score_engajamento:
                return "ğŸš¨ Risco: Queda Receita"
            else:
                return "ğŸš¨ Risco: Queda Engajamento"


def get_expectativa_vip(nivel: int) -> Dict:
    """
    Retorna expectativas de compra por nÃ­vel VIP
    Usado para comparar performance real vs esperada
    """
    expectativas = {
        1: {'compras_7d': 1, 'ticket_medio': 20, 'label': 'Iniciante'},
        2: {'compras_7d': 2, 'ticket_medio': 35, 'label': 'Regular'},
        3: {'compras_7d': 3, 'ticket_medio': 50, 'label': 'Fiel'},
        4: {'compras_7d': 4, 'ticket_medio': 75, 'label': 'Premium'},
        5: {'compras_7d': 5, 'ticket_medio': 100, 'label': 'Elite'}
    }
    return expectativas.get(int(nivel) if pd.notna(nivel) else 1, expectativas[1])


def calcular_status_vip(row: pd.Series) -> str:
    """
    Compara performance do jogador com a expectativa do seu VIP
    Retorna: acima, na_media, abaixo, critico
    """
    nivel = row.get('nivel_vip', 1)
    expectativa = get_expectativa_vip(nivel)
    
    qtd_real = row.get('qtd_compras_7d', 0) or 0
    ticket_real = row.get('ticket_medio_7d', 0) or 0
    
    qtd_esperada = expectativa['compras_7d']
    ticket_esperado = expectativa['ticket_medio']
    
    # Calcula performance (0 a 200%)
    perf_qtd = (qtd_real / qtd_esperada * 100) if qtd_esperada > 0 else 0
    perf_ticket = (ticket_real / ticket_esperado * 100) if ticket_esperado > 0 else 0
    
    # MÃ©dia ponderada: quantidade pesa mais
    performance = (perf_qtd * 0.6) + (perf_ticket * 0.4)
    
    if performance >= 120:
        return "ğŸ† Superando"
    elif performance >= 90:
        return "âœ… Dentro da meta"
    elif performance >= 60:
        return "âš ï¸ Abaixo do esperado"
    else:
        return "ğŸš¨ CrÃ­tico"


def detectar_tipo_arquivo(filename: str) -> str:
    """Detecta o tipo de arquivo baseado na extensÃ£o"""
    if filename.lower().endswith('.csv'):
        return 'csv'
    elif filename.lower().endswith(('.xlsx', '.xls')):
        return 'excel'
    else:
        return 'unknown'


def processar_dados_jogadores(df: pd.DataFrame) -> tuple[pd.DataFrame, Dict]:
    """Processa DataFrame e adiciona scores calculados com parÃ¢metros dinÃ¢micos"""
    
    # Calcula parÃ¢metros dinÃ¢micos a partir dos dados
    params = HealthScoreCalculator.calcular_params_dinamicos(df)
    
    # Inicializa calculador com parÃ¢metros dinÃ¢micos
    calc = HealthScoreCalculator(params)
    
    # Normaliza nomes de colunas
    df.columns = df.columns.str.lower().str.strip()
    
    # Renomeia colunas comuns do CRM para padrÃ£o
    if 'pid' in df.columns and 'player_id' not in df.columns:
        df = df.rename(columns={'pid': 'player_id'})
    
    # Calcula scores individuais
    df['score_login'] = calc.calcular_score_login(df)
    df['score_engajamento'] = calc.calcular_score_engajamento(df)
    df['score_compras'] = calc.calcular_score_compras(df)
    
    # Calcula score geral
    df['score_geral'] = df.apply(calc.calcular_score_geral, axis=1)
    
    # Categoriza jogadores
    df['categoria'] = df.apply(calc.categorizar_jogador, axis=1)
    
    # Status de atividade
    df['ativo'] = df['score_login'] >= 50
    
    # Identifica regiÃ£o do jogador
    if 'translation' in df.columns:
        df['regiao'] = df['translation'].apply(get_regiao)
    else:
        df['regiao'] = 'int'  # Default: Internacional
    
    # Define aÃ§Ã£o sugerida baseada na categoria
    # Define aÃ§Ã£o sugerida baseada na categoria
    acoes_crm = {
        'â­ Elite': 'âœ¨ BenefÃ­cios exclusivos + PersonalizaÃ§Ã£o',
        'ğŸ† VIP Ativo': 'ğŸ Recompensas + Upsell',
        'ğŸ“ˆ Bom': 'ğŸ’³ Incentivar mais compras',
        'ğŸ“Š EstÃ¡vel': 'ğŸ“± Manter ritmo + NotificaÃ§Ãµes',
        'âš ï¸ AtenÃ§Ã£o': 'ğŸ”” Reengajamento ativo',
        'ğŸš¨ Risco Alto': 'âš¡ Oferta especial urgente',
        'ğŸš¨ Risco: Queda Receita': 'ğŸ›’ Foco em conversÃ£o',
        'ğŸš¨ Risco: Queda Engajamento': 'ğŸ® Foco em atividades',
        'ğŸ’ Churn Iminente': 'ğŸ“ LigaÃ§Ã£o + Oferta Ãºltima chance',
        'ğŸ’° Oportunidade VIP': 'ğŸ’ Atendimento VIP + Oferta personalizada',
        'ğŸ’° Oportunidade': 'ğŸ Oferta de boas-vindas + Onboarding',
        'ğŸ¯ Potencial': 'ğŸ“ˆ Nutrir + Incentivo gradual'
    }
    
    df['acao_sugerida'] = df['categoria'].map(acoes_crm)
    df['acao_sugerida'] = df['acao_sugerida'].fillna('ğŸ“Š Acompanhamento geral')
    
    # Adiciona expectativa e status por VIP
    if 'nivel_vip' in df.columns:
        df['vip_expectativa'] = df['nivel_vip'].apply(lambda x: get_expectativa_vip(x)['label'])
        df['vip_status'] = df.apply(calcular_status_vip, axis=1)
    
    # Adiciona informaÃ§Ãµes de VIP
    if 'nivel_vip' in df.columns:
        df['vip_nome'] = df['nivel_vip'].apply(lambda x: get_vip_info(int(x) if pd.notna(x) else 0)['nome'])
        df['vip_cor'] = df['nivel_vip'].apply(lambda x: get_vip_info(int(x) if pd.notna(x) else 0)['cor'])
        df['vip_icone'] = df['nivel_vip'].apply(lambda x: get_vip_info(int(x) if pd.notna(x) else 0)['icone'])
    
    return df, params


def salvar_snapshot(resumo: Dict, filtros: Dict = None, data_custom: str = None) -> int:
    """Salva um snapshot do dia no banco de dados"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    # Usa data customizada (do arquivo) ou data atual
    if data_custom:
        data_snapshot = data_custom
    else:
        data_snapshot = datetime.now().strftime("%Y-%m-%d")
    
    agora = datetime.now().isoformat()
    
    filtros = filtros or {}
    filtro_regiao = filtros.get('regiao', 'all')
    filtro_vip = filtros.get('vip', 'all')
    
    # Agrupa as 12 categorias com emojis nas 6 categorias do banco
    contagem = resumo.get('contagem_por_categoria', {})
    
    # Mapeamento: 12 novas categorias -> 6 grupos do banco
    cluster_elite = contagem.get('â­ Elite', 0) + contagem.get('ğŸ’° Oportunidade VIP', 0)
    cluster_muito_bom = (contagem.get('ğŸ† VIP Ativo', 0) + contagem.get('ğŸ“ˆ Bom', 0) + 
                         contagem.get('ğŸ’° Oportunidade', 0) + contagem.get('ğŸ¯ Potencial', 0))
    cluster_estavel = contagem.get('ğŸ“Š EstÃ¡vel', 0)
    cluster_baixo = (contagem.get('âš ï¸ AtenÃ§Ã£o', 0) + contagem.get('ğŸš¨ Risco Alto', 0) + 
                     contagem.get('ğŸ’ Churn Iminente', 0))
    cluster_risco_receita = contagem.get('ğŸš¨ Risco: Queda Receita', 0)
    cluster_risco_engajamento = contagem.get('ğŸš¨ Risco: Queda Engajamento', 0)
    
    # Insere snapshot principal
    cursor.execute('''
        INSERT INTO snapshots (
            data, data_timestamp, total_jogadores, percentual_ativos,
            media_score_geral, media_score_login, media_score_engajamento, media_score_compras,
            cluster_elite, cluster_muito_bom, cluster_estavel, cluster_baixo,
            cluster_risco_receita, cluster_risco_engajamento,
            filtro_regiao, filtro_vip
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    ''', (
        data_snapshot, agora,
        resumo.get('total_jogadores', 0),
        resumo.get('percentual_ativos', 0),
        resumo.get('media_pontuacao_geral', 0),
        resumo.get('media_saude_login', 0),
        resumo.get('media_saude_engajamento', 0),
        resumo.get('media_saude_compras', 0),
        cluster_elite,
        cluster_muito_bom,
        cluster_estavel,
        cluster_baixo,
        cluster_risco_receita,
        cluster_risco_engajamento,
        filtro_regiao, filtro_vip
    ))
    
    snapshot_id = cursor.lastrowid
    
    # Insere detalhes dos clusters (jÃ¡ calculados acima)
    total = resumo.get('total_jogadores', 1)
    
    clusters_info = [
        ('Elite', cluster_elite),
        ('Muito bom', cluster_muito_bom),
        ('EstÃ¡vel', cluster_estavel),
        ('Baixo', cluster_baixo),
        ('Risco: Queda em Receita', cluster_risco_receita),
        ('Risco: Queda em Engajamento', cluster_risco_engajamento),
    ]
    
    for nome, qtd in clusters_info:
        cursor.execute('''
            INSERT INTO clusters_dia (snapshot_id, cluster_nome, quantidade, percentual, score_compras_medio, score_engajamento_medio)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (snapshot_id, nome, qtd, round(qtd/total*100, 2) if total > 0 else 0, 0, 0))
    
    conn.commit()
    conn.close()
    return snapshot_id


def salvar_player_snapshots(df: pd.DataFrame, data_snapshot: str = None, campanha_nome: str = None):
    """
    Salva os dados individuais de cada jogador para acompanhamento de evoluÃ§Ã£o.
    Permite analisar flutuaÃ§Ã£o entre clusters e impacto de campanhas.
    """
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    if data_snapshot is None:
        data_snapshot = datetime.now().strftime("%Y-%m-%d")
    
    agora = datetime.now().isoformat()
    
    # Prepara dados para inserÃ§Ã£o em lote
    player_data = []
    
    for _, row in df.iterrows():
        player_data.append((
            str(row.get('player_id', row.get('pid', ''))),
            data_snapshot,
            agora,
            float(row.get('score_geral', 0)),
            float(row.get('score_engajamento', 0)),
            float(row.get('score_compras', 0)),
            float(row.get('score_login', 0)),
            int(row.get('qtd_compras_7d', 0) or 0),
            float(row.get('ticket_medio_7d', 0) or 0),
            int(row.get('qtd_torneios_3d', 0) or 0),
            int(row.get('qtd_maratonas_3d', 0) or 0),
            int(row.get('qtd_missoes_3d', 0) or 0),
            int(row.get('qtd_promos_3d', 0) or 0),
            int(row.get('qtd_logins_3d', 0) or 0),
            str(row.get('categoria', '')),
            int(row.get('nivel_vip', 1) or 1),
            str(row.get('regiao', 'int')),
            campanha_nome
        ))
    
    # Insere em lote usando INSERT OR REPLACE para evitar duplicatas
    # Se jÃ¡ existir registro para este player_id + data, atualiza os dados
    cursor.executemany('''
        INSERT OR REPLACE INTO player_snapshots (
            player_id, data, data_timestamp,
            score_geral, score_engajamento, score_compras, score_login,
            qtd_compras_7d, ticket_medio_7d,
            qtd_torneios_3d, qtd_maratonas_3d, qtd_missoes_3d, qtd_promos_3d, qtd_logins_3d,
            categoria, nivel_vip, regiao, campanha_nome
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    ''', player_data)
    
    conn.commit()
    conn.close()
    
    return len(player_data)


def get_evolucao_player(player_id: str, dias: int = 30) -> Dict:
    """
    Retorna a evoluÃ§Ã£o histÃ³rica de um jogador especÃ­fico.
    Ãštil para analisar flutuaÃ§Ã£o entre clusters e impacto de campanhas.
    """
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    # Log para debug
    print(f"[DEBUG] Buscando evoluÃ§Ã£o do jogador {player_id} nos Ãºltimos {dias} dias")
    
    cursor.execute('''
        SELECT * FROM player_snapshots 
        WHERE player_id = ? 
        AND data >= date('now', '-{} days')
        ORDER BY data ASC
    '''.format(dias), (player_id,))
    
    rows = cursor.fetchall()
    
    print(f"[DEBUG] Encontrados {len(rows)} registros para o jogador {player_id}")
    for row in rows:
        print(f"[DEBUG]   - Data: {row['data']}, Categoria: {row['categoria']}")
    
    if not rows:
        conn.close()
        return {"error": "Nenhum histÃ³rico encontrado para este jogador"}
    
    # Processa evoluÃ§Ã£o
    evolucao = []
    flutuacao_clusters = []
    variacoes = []
    
    for i, row in enumerate(rows):
        evolucao.append({
            "data": row['data'],
            "score_geral": round(row['score_geral'], 2),
            "score_engajamento": round(row['score_engajamento'], 2),
            "score_compras": round(row['score_compras'], 2),
            "categoria": row['categoria'],
            "campanha_nome": row['campanha_nome']
        })
        
        flutuacao_clusters.append(row['categoria'])
        
        # Calcula variaÃ§Ã£o em relaÃ§Ã£o ao dia anterior
        if i > 0:
            var_geral = row['score_geral'] - rows[i-1]['score_geral']
            var_engajamento = row['score_engajamento'] - rows[i-1]['score_engajamento']
            var_compras = row['score_compras'] - rows[i-1]['score_compras']
            
            variacoes.append({
                "data": row['data'],
                "variacao_geral": round(var_geral, 2),
                "variacao_engajamento": round(var_engajamento, 2),
                "variacao_compras": round(var_compras, 2),
                "mudanca_cluster": row['categoria'] != rows[i-1]['categoria']
            })
    
    # AnÃ¡lise de clusters
    cluster_atual = rows[-1]['categoria']
    dias_no_cluster_atual = 0
    for row in reversed(rows):
        if row['categoria'] == cluster_atual:
            dias_no_cluster_atual += 1
        else:
            break
    
    # MÃ©tricas de compras e engajamento
    metricas_compras = {
        "tendencia": "crescente" if len(rows) > 1 and rows[-1]['score_compras'] > rows[0]['score_compras'] else "decrescente",
        "maior_score": round(max(r['score_compras'] for r in rows), 2),
        "menor_score": round(min(r['score_compras'] for r in rows), 2),
        "media": round(sum(r['score_compras'] for r in rows) / len(rows), 2)
    }
    
    metricas_engajamento = {
        "tendencia": "crescente" if len(rows) > 1 and rows[-1]['score_engajamento'] > rows[0]['score_engajamento'] else "decrescente",
        "maior_score": round(max(r['score_engajamento'] for r in rows), 2),
        "menor_score": round(min(r['score_engajamento'] for r in rows), 2),
        "media": round(sum(r['score_engajamento'] for r in rows) / len(rows), 2)
    }
    
    conn.close()
    
    return {
        "player_id": player_id,
        "total_registros": len(rows),
        "periodo_dias": dias,
        "cluster_atual": cluster_atual,
        "dias_no_cluster_atual": dias_no_cluster_atual,
        "historico_clusters": list(dict.fromkeys(flutuacao_clusters)),  # Remove duplicatas mantendo ordem
        "evolucao": evolucao,
        "variacoes": variacoes,
        "metricas_compras": metricas_compras,
        "metricas_engajamento": metricas_engajamento,
        "resumo": {
            "mudancas_cluster": sum(1 for v in variacoes if v['mudanca_cluster']),
            "variacao_total_geral": round(rows[-1]['score_geral'] - rows[0]['score_geral'], 2) if len(rows) > 1 else 0,
            "variacao_total_compras": round(rows[-1]['score_compras'] - rows[0]['score_compras'], 2) if len(rows) > 1 else 0,
            "variacao_total_engajamento": round(rows[-1]['score_engajamento'] - rows[0]['score_engajamento'], 2) if len(rows) > 1 else 0
        }
    }


def get_players_com_flutuacao(cluster_origem: str = None, cluster_destino: str = None, 
                               dias: int = 7, tipo_flutuacao: str = 'melhora') -> List[Dict]:
    """
    Identifica jogadores que mudaram de cluster significativamente.
    
    tipo_flutuacao: 'melhora' (ex: Baixo -> Bom), 'piora' (ex: Bom -> Baixo), 'qualquer'
    """
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    # Busca todos os jogadores com histÃ³rico no perÃ­odo
    cursor.execute('''
        SELECT player_id, COUNT(*) as total_registros
        FROM player_snapshots 
        WHERE data >= date('now', '-{} days')
        GROUP BY player_id
        HAVING total_registros >= 2
    '''.format(dias))
    
    players = cursor.fetchall()
    
    resultado = []
    
    for player in players:
        player_id = player['player_id']
        
        # Busca primeiro e Ãºltimo registro do perÃ­odo
        cursor.execute('''
            SELECT * FROM player_snapshots 
            WHERE player_id = ? 
            AND data >= date('now', '-{} days')
            ORDER BY data ASC
            LIMIT 1
        '''.format(dias), (player_id,))
        
        primeiro = cursor.fetchone()
        
        cursor.execute('''
            SELECT * FROM player_snapshots 
            WHERE player_id = ? 
            AND data >= date('now', '-{} days')
            ORDER BY data DESC
            LIMIT 1
        '''.format(dias), (player_id,))
        
        ultimo = cursor.fetchone()
        
        if not primeiro or not ultimo:
            continue
        
        # Verifica filtros de cluster
        if cluster_origem and primeiro['categoria'] != cluster_origem:
            continue
        if cluster_destino and ultimo['categoria'] != cluster_destino:
            continue
        
        # Determina se Ã© melhora ou piora
        # Ordem de "qualidade": Elite > VIP Ativo > Bom > EstÃ¡vel > AtenÃ§Ã£o > Risco
        ordem_clusters = ['â­ Elite', 'ğŸ† VIP Ativo', 'ğŸ“ˆ Bom', 'ğŸ“Š EstÃ¡vel', 
                         'âš ï¸ AtenÃ§Ã£o', 'ğŸš¨ Risco Alto', 'ğŸš¨ Risco: Queda Receita', 
                         'ğŸš¨ Risco: Queda Engajamento', 'ğŸ’ Churn Iminente']
        
        idx_origem = ordem_clusters.index(primeiro['categoria']) if primeiro['categoria'] in ordem_clusters else 999
        idx_destino = ordem_clusters.index(ultimo['categoria']) if ultimo['categoria'] in ordem_clusters else 999
        
        melhorou = idx_destino < idx_origem
        piorou = idx_destino > idx_origem
        
        if tipo_flutuacao == 'melhora' and not melhorou:
            continue
        if tipo_flutuacao == 'piora' and not piorou:
            continue
        if tipo_flutuacao == 'qualquer' and idx_origem == idx_destino:
            continue
        
        resultado.append({
            "player_id": player_id,
            "cluster_origem": primeiro['categoria'],
            "cluster_destino": ultimo['categoria'],
            "data_inicio": primeiro['data'],
            "data_fim": ultimo['data'],
            "variacao_score": round(ultimo['score_geral'] - primeiro['score_geral'], 2),
            "variacao_compras": round(ultimo['score_compras'] - primeiro['score_compras'], 2),
            "variacao_engajamento": round(ultimo['score_engajamento'] - primeiro['score_engajamento'], 2),
            "melhorou": melhorou,
            "campanha_inicio": primeiro['campanha_nome'],
            "campanha_fim": ultimo['campanha_nome']
        })
    
    conn.close()
    
    # Ordena por maior variaÃ§Ã£o de score
    resultado.sort(key=lambda x: abs(x['variacao_score']), reverse=True)
    
    return resultado


def listar_historico(regiao: str = None, vip: str = None, dias: int = 30) -> List[Dict]:
    """Lista histÃ³rico de snapshots com filtros opcionais"""
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    query = "SELECT * FROM snapshots WHERE 1=1"
    params = []
    
    if regiao and regiao != 'all':
        query += " AND filtro_regiao = ?"
        params.append(regiao)
    if vip and vip != 'all':
        query += " AND filtro_vip = ?"
        params.append(vip)
    
    query += " ORDER BY data ASC LIMIT ?"  # Ordena por data do snapshot (mais antigo primeiro)
    params.append(dias)
    
    cursor.execute(query, params)
    rows = cursor.fetchall()
    
    historico = []
    for row in rows:
        historico.append({
            'id': row['id'],
            'data': row['data'],
            'data_timestamp': row['data_timestamp'],
            'total_jogadores': row['total_jogadores'],
            'percentual_ativos': row['percentual_ativos'],
            'media_score_geral': row['media_score_geral'],
            'media_score_login': row['media_score_login'],
            'media_score_engajamento': row['media_score_engajamento'],
            'media_score_compras': row['media_score_compras'],
            'clusters': {
                'â­ Elite': row['cluster_elite'],
                'ğŸ† VIP Ativo': row['cluster_muito_bom'],
                'ğŸ“Š EstÃ¡vel': row['cluster_estavel'],
                'âš ï¸ AtenÃ§Ã£o': row['cluster_baixo'],
                'ğŸš¨ Risco: Queda Receita': row['cluster_risco_receita'],
                'ğŸš¨ Risco: Queda Engajamento': row['cluster_risco_engajamento'],
            },
            'filtro_regiao': row['filtro_regiao'],
            'filtro_vip': row['filtro_vip'],
        })
    
    conn.close()
    return historico


def deletar_snapshot(snapshot_id: int = None, data: str = None) -> bool:
    """Deleta um snapshot por ID ou por data"""
    print(f"[DEBUG] deletar_snapshot chamado - snapshot_id={snapshot_id}, data={data}")
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    try:
        total_afetado = 0
        
        if snapshot_id:
            print(f"[DEBUG] Verificando se snapshot {snapshot_id} existe...")
            cursor.execute('SELECT id FROM snapshots WHERE id = ?', (snapshot_id,))
            existe = cursor.fetchone()
            print(f"[DEBUG] Snapshot existe: {existe is not None}")
            
            if not existe:
                conn.close()
                return False
            
            # Deleta clusters primeiro (foreign key)
            print(f"[DEBUG] Deletando clusters do snapshot {snapshot_id}...")
            cursor.execute('DELETE FROM clusters_dia WHERE snapshot_id = ?', (snapshot_id,))
            clusters_deletados = cursor.rowcount
            print(f"[DEBUG] Clusters deletados: {clusters_deletados}")
            total_afetado += clusters_deletados
            
            # Deleta snapshot
            print(f"[DEBUG] Deletando snapshot {snapshot_id}...")
            cursor.execute('DELETE FROM snapshots WHERE id = ?', (snapshot_id,))
            snapshots_deletados = cursor.rowcount
            print(f"[DEBUG] Snapshots deletados: {snapshots_deletados}")
            total_afetado += snapshots_deletados
            
        elif data:
            # Busca IDs dos snapshots da data
            cursor.execute('SELECT id FROM snapshots WHERE data = ?', (data,))
            ids = cursor.fetchall()
            print(f"[DEBUG] Encontrados {len(ids)} snapshots para data {data}")
            for (sid,) in ids:
                cursor.execute('DELETE FROM clusters_dia WHERE snapshot_id = ?', (sid,))
                total_afetado += cursor.rowcount
            cursor.execute('DELETE FROM snapshots WHERE data = ?', (data,))
            total_afetado += cursor.rowcount
        else:
            print(f"[DEBUG] Nenhum ID ou data fornecido")
            conn.close()
            return False
        
        conn.commit()
        conn.close()
        print(f"[DEBUG] Total registros afetados: {total_afetado}")
        return total_afetado > 0
    except Exception as e:
        print(f"[ERROR] Erro ao deletar snapshot: {e}")
        import traceback
        traceback.print_exc()
        conn.close()
        return False


def comparar_periodos(data_inicio: str, data_fim: str) -> Dict:
    """Compara dados entre dois perÃ­odos"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    cursor.execute('''
        SELECT * FROM snapshots 
        WHERE data BETWEEN ? AND ?
        ORDER BY data
    ''', (data_inicio, data_fim))
    
    rows = cursor.fetchall()
    conn.close()
    
    if not rows:
        return {'mensagem': 'Nenhum dado encontrado para o perÃ­odo'}
    
    # Calcula mÃ©dias e tendÃªncias
    total_dias = len(rows)
    media_jogadores = sum(r[3] for r in rows) / total_dias
    media_ativos = sum(r[4] for r in rows) / total_dias
    media_score = sum(r[5] for r in rows) / total_dias
    
    # TendÃªncia (Ãºltimo vs primeiro dia)
    primeira_data = rows[0]
    ultima_data = rows[-1]
    
    return {
        'periodo': {'inicio': data_inicio, 'fim': data_fim, 'dias': total_dias},
        'medias': {
            'total_jogadores': round(media_jogadores, 0),
            'percentual_ativos': round(media_ativos, 2),
            'score_geral': round(media_score, 2),
        },
        'tendencia': {
            'total_jogadores': ultima_data[3] - primeira_data[3],
            'percentual_ativos': round(ultima_data[4] - primeira_data[4], 2),
            'score_geral': round(ultima_data[5] - primeira_data[5], 2),
        },
        'evolucao_diaria': [
            {
                'data': r[1],
                'total_jogadores': r[3],
                'percentual_ativos': r[4],
                'score_geral': r[5],
            } for r in rows
        ]
    }


def clean_for_json(obj):
    """Limpa valores NaN, Infinity para serializaÃ§Ã£o JSON"""
    if isinstance(obj, dict):
        return {k: clean_for_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [clean_for_json(item) for item in obj]
    elif isinstance(obj, float):
        if pd.isna(obj):
            return 0.0
        elif np.isinf(obj):
            return 999999.99 if obj > 0 else -999999.99
        return round(obj, 2)
    elif isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj) if not (pd.isna(obj) or np.isinf(obj)) else 0.0
    else:
        return obj


def gerar_resumo_dashboard(df: pd.DataFrame, params: Dict) -> Dict[str, Any]:
    """Gera resumo estatÃ­stico para o dashboard"""
    total = len(df)
    ativos = df['ativo'].sum()
    
    # Identifica coluna de ID
    id_col = 'player_id' if 'player_id' in df.columns else df.columns[0]
    
    # Calcula contagem por categoria
    contagem_categorias = df['categoria'].value_counts()
    
    resumo = {
        "data": datetime.now().strftime("%d/%m/%Y"),
        "total_jogadores": total,
        "percentual_ativos": round(ativos / total * 100, 2) if total > 0 else 0,
        "media_saude_login": round(df['score_login'].mean(), 2),
        "media_saude_engajamento": round(df['score_engajamento'].mean(), 2),
        "media_saude_compras": round(df['score_compras'].mean(), 2),
        "media_pontuacao_geral": round(df['score_geral'].mean(), 2),
        "distribuicao_categorias": {
            "elite": round((df['categoria'] == 'â­ Elite').sum() / total * 100, 2) if total > 0 else 0,
            "vip_ativo": round((df['categoria'] == 'ğŸ† VIP Ativo').sum() / total * 100, 2) if total > 0 else 0,
            "bom": round((df['categoria'] == 'ğŸ“ˆ Bom').sum() / total * 100, 2) if total > 0 else 0,
            "estavel": round((df['categoria'] == 'ğŸ“Š EstÃ¡vel').sum() / total * 100, 2) if total > 0 else 0,
            "atencao": round((df['categoria'] == 'âš ï¸ AtenÃ§Ã£o').sum() / total * 100, 2) if total > 0 else 0,
            "risco_alto": round((df['categoria'] == 'ğŸš¨ Risco Alto').sum() / total * 100, 2) if total > 0 else 0,
            "risco_receita": round((df['categoria'] == 'ğŸš¨ Risco: Queda Receita').sum() / total * 100, 2) if total > 0 else 0,
            "risco_engajamento": round((df['categoria'] == 'ğŸš¨ Risco: Queda Engajamento').sum() / total * 100, 2) if total > 0 else 0,
            "churn_iminente": round((df['categoria'] == 'ğŸ’ Churn Iminente').sum() / total * 100, 2) if total > 0 else 0,
            "oportunidade_vip": round((df['categoria'] == 'ğŸ’° Oportunidade VIP').sum() / total * 100, 2) if total > 0 else 0,
            "oportunidade": round((df['categoria'] == 'ğŸ’° Oportunidade').sum() / total * 100, 2) if total > 0 else 0,
            "potencial": round((df['categoria'] == 'ğŸ¯ Potencial').sum() / total * 100, 2) if total > 0 else 0,
        },
        "contagem_por_categoria": contagem_categorias.to_dict(),
        "parametros_calculados": params,
        "benchmarks": {
            "torneios_por_dia": round(params.get('torneios_por_dia', 0), 2),
            "maratonas_por_dia": round(params.get('maratonas_por_dia', 0), 2),
            "missoes_por_dia": round(params.get('missoes_por_dia', 0), 2),
            "promos_por_dia": round(params.get('promos_por_dia', 0), 2),
            "logins_3d": round(params.get('media_logins_3d', 0), 2),
        },
        "estatisticas": {
            # MÃ©dias (MÃ‰DIA no Excel)
            "media_torneios_3d": round(params.get('media_torneios_3d', 0), 2),
            "media_maratonas_3d": round(params.get('media_maratonas_3d', 0), 2),
            "media_missoes_3d": round(params.get('media_missoes_3d', 0), 2),
            "media_promos_3d": round(params.get('media_promos_3d', 0), 2),
            "media_logins_3d": round(params.get('media_logins_3d', 0), 2),
            # Desvios PadrÃ£o (DESVPAD.P no Excel)
            "desvpad_torneios_3d": round(params.get('desvpad_torneios_3d', 0), 2),
            "desvpad_maratonas_3d": round(params.get('desvpad_maratonas_3d', 0), 2),
            "desvpad_missoes_3d": round(params.get('desvpad_missoes_3d', 0), 2),
            "desvpad_promos_3d": round(params.get('desvpad_promos_3d', 0), 2),
            "desvpad_logins_3d": round(params.get('desvpad_logins_3d', 0), 2),
            # Medianas (MED no Excel)
            "mediana_torneios_3d": round(params.get('mediana_torneios_3d', 0), 2),
            "mediana_maratonas_3d": round(params.get('mediana_maratonas_3d', 0), 2),
            "mediana_missoes_3d": round(params.get('mediana_missoes_3d', 0), 2),
            "mediana_promos_3d": round(params.get('mediana_promos_3d', 0), 2),
            "mediana_logins_3d": round(params.get('mediana_logins_3d', 0), 2),
        },
        "top_jogadores": df.nlargest(10, 'score_geral')[[id_col, 
                                                          'score_login', 'score_engajamento', 
                                                          'score_compras', 'score_geral', 
                                                          'categoria', 'acao_sugerida']].to_dict('records'),
        "jogadores_risco_receita": df[df['categoria'] == 'Risco: Queda em Receita'][[id_col, 
                                                                          'score_geral', 'score_engajamento', 'score_compras',
                                                                          'categoria', 'acao_sugerida']].head(50).to_dict('records'),
        "jogadores_risco_engajamento": df[df['categoria'] == 'Risco: Queda em Engajamento'][[id_col, 
                                                                          'score_geral', 'score_engajamento', 'score_compras',
                                                                          'categoria', 'acao_sugerida']].head(50).to_dict('records'),
    }
    
    # Adiciona anÃ¡lise por regiÃ£o
    if 'regiao' in df.columns:
        resumo["analise_regiao"] = {}
        resumo["distribuicao_regiao"] = {}
        
        for regiao in ['es', 'br', 'int']:
            df_regiao = df[df['regiao'] == regiao]
            if len(df_regiao) > 0:
                resumo["analise_regiao"][regiao] = {
                    "codigo": regiao,
                    "nome": get_regiao_nome(regiao),
                    "quantidade": len(df_regiao),
                    "percentual": round(len(df_regiao) / total * 100, 2),
                    "score_geral_medio": round(df_regiao['score_geral'].mean(), 2),
                    "score_login_medio": round(df_regiao['score_login'].mean(), 2),
                    "score_engajamento_medio": round(df_regiao['score_engajamento'].mean(), 2),
                    "score_compras_medio": round(df_regiao['score_compras'].mean(), 2),
                    "percentual_ativos": round((df_regiao['ativo'].sum() / len(df_regiao) * 100), 2),
                    "distribuicao_categorias": {
                        "elite": round((df_regiao['categoria'] == 'â­ Elite').sum() / len(df_regiao) * 100, 2),
                        "vip_ativo": round((df_regiao['categoria'] == 'ğŸ† VIP Ativo').sum() / len(df_regiao) * 100, 2),
                        "bom": round((df_regiao['categoria'] == 'ğŸ“ˆ Bom').sum() / len(df_regiao) * 100, 2),
                        "estavel": round((df_regiao['categoria'] == 'ğŸ“Š EstÃ¡vel').sum() / len(df_regiao) * 100, 2),
                        "atencao": round((df_regiao['categoria'] == 'âš ï¸ AtenÃ§Ã£o').sum() / len(df_regiao) * 100, 2),
                        "risco_alto": round((df_regiao['categoria'] == 'ğŸš¨ Risco Alto').sum() / len(df_regiao) * 100, 2),
                        "risco_receita": round((df_regiao['categoria'] == 'ğŸš¨ Risco: Queda Receita').sum() / len(df_regiao) * 100, 2),
                        "risco_engajamento": round((df_regiao['categoria'] == 'ğŸš¨ Risco: Queda Engajamento').sum() / len(df_regiao) * 100, 2),
                        "churn_iminente": round((df_regiao['categoria'] == 'ğŸ’ Churn Iminente').sum() / len(df_regiao) * 100, 2),
                        "oportunidade_vip": round((df_regiao['categoria'] == 'ğŸ’° Oportunidade VIP').sum() / len(df_regiao) * 100, 2),
                        "oportunidade": round((df_regiao['categoria'] == 'ğŸ’° Oportunidade').sum() / len(df_regiao) * 100, 2),
                        "potencial": round((df_regiao['categoria'] == 'ğŸ¯ Potencial').sum() / len(df_regiao) * 100, 2),
                    },
                    "top_3": df_regiao.nlargest(3, 'score_geral')[[id_col, 'score_geral', 'categoria', 'regiao']].to_dict('records')
                }
                resumo["distribuicao_regiao"][regiao] = len(df_regiao)
    
    # Adiciona anÃ¡lise por nÃ­vel VIP
    if 'nivel_vip' in df.columns:
        resumo["analise_vip"] = {}
        resumo["distribuicao_vip"] = {}
        
        for nivel in sorted(df['nivel_vip'].dropna().unique()):
            nivel_int = int(nivel)
            df_vip = df[df['nivel_vip'] == nivel]
            vip_info = get_vip_info(nivel_int)
            
            resumo["analise_vip"][f"vip_{nivel_int}"] = {
                "nivel": nivel_int,
                "nome": vip_info['nome'],
                "cor": vip_info['cor'],
                "icone": vip_info['icone'],
                "quantidade": len(df_vip),
                "percentual": round(len(df_vip) / total * 100, 2),
                "score_geral_medio": round(df_vip['score_geral'].mean(), 2),
                "score_login_medio": round(df_vip['score_login'].mean(), 2),
                "score_engajamento_medio": round(df_vip['score_engajamento'].mean(), 2),
                "score_compras_medio": round(df_vip['score_compras'].mean(), 2),
                "percentual_ativos": round((df_vip['ativo'].sum() / len(df_vip) * 100), 2) if len(df_vip) > 0 else 0,
                "distribuicao_categorias": {
                    "elite": round((df_vip['categoria'] == 'â­ Elite').sum() / len(df_vip) * 100, 2),
                    "vip_ativo": round((df_vip['categoria'] == 'ğŸ† VIP Ativo').sum() / len(df_vip) * 100, 2),
                    "bom": round((df_vip['categoria'] == 'ğŸ“ˆ Bom').sum() / len(df_vip) * 100, 2),
                    "estavel": round((df_vip['categoria'] == 'ğŸ“Š EstÃ¡vel').sum() / len(df_vip) * 100, 2),
                    "atencao": round((df_vip['categoria'] == 'âš ï¸ AtenÃ§Ã£o').sum() / len(df_vip) * 100, 2),
                    "risco_alto": round((df_vip['categoria'] == 'ğŸš¨ Risco Alto').sum() / len(df_vip) * 100, 2),
                    "risco_receita": round((df_vip['categoria'] == 'ğŸš¨ Risco: Queda Receita').sum() / len(df_vip) * 100, 2),
                    "risco_engajamento": round((df_vip['categoria'] == 'ğŸš¨ Risco: Queda Engajamento').sum() / len(df_vip) * 100, 2),
                    "churn_iminente": round((df_vip['categoria'] == 'ğŸ’ Churn Iminente').sum() / len(df_vip) * 100, 2),
                    "oportunidade_vip": round((df_vip['categoria'] == 'ğŸ’° Oportunidade VIP').sum() / len(df_vip) * 100, 2),
                    "oportunidade": round((df_vip['categoria'] == 'ğŸ’° Oportunidade').sum() / len(df_vip) * 100, 2),
                    "potencial": round((df_vip['categoria'] == 'ğŸ¯ Potencial').sum() / len(df_vip) * 100, 2),
                },
                "top_3": df_vip.nlargest(3, 'score_geral')[[id_col, 'score_geral', 'categoria']].to_dict('records')
            }
            
            resumo["distribuicao_vip"][vip_info['nome']] = len(df_vip)
    
    return resumo


@app.get("/", response_class=HTMLResponse)
async def read_root():
    """Serve a pÃ¡gina principal"""
    index_path = os.path.join(TEMPLATES_DIR, "index.html")
    if not os.path.exists(index_path):
        # Fallback para caminho relativo
        index_path = "templates/index.html"
    return FileResponse(index_path)


@app.post("/api/upload")
async def upload_file(file: UploadFile = File(...)):
    """Recebe upload de CSV ou Excel e processa os dados com parÃ¢metros dinÃ¢micos"""
    global cached_data
    
    file_type = detectar_tipo_arquivo(file.filename)
    
    if file_type == 'unknown':
        raise HTTPException(status_code=400, detail="Arquivo deve ser CSV ou Excel (.xlsx/.xls)")
    
    try:
        contents = await file.read()
        
        if file_type == 'csv':
            df = pd.read_csv(io.StringIO(contents.decode('utf-8')), sep=None, engine='python')
        else:
            df = pd.read_excel(io.BytesIO(contents))
        
        # Processa dados com parÃ¢metros dinÃ¢micos (sem salvar no histÃ³rico ainda)
        df_processado, params = processar_dados_jogadores(df)
        
        # Gera resumo
        resumo = gerar_resumo_dashboard(df_processado, params)
        
        # Armazena em cache
        cached_data = {
            'df': df_processado,
            'resumo': resumo,
            'params': params,
            'timestamp': datetime.now()
        }
        
        # Limpa valores para JSON
        resumo_clean = clean_for_json(resumo)
        
        return {
            "success": True,
            "message": f"Processados {len(df)} jogadores com parÃ¢metros dinÃ¢micos",
            "resumo": resumo_clean
        }
        
    except Exception as e:
        import traceback
        error_msg = f"Erro ao processar arquivo: {str(e)}"
        print(f"\n{'='*60}")
        print("ERRO NO UPLOAD:")
        print(f"{'='*60}")
        print(error_msg)
        print("\nTraceback:")
        traceback.print_exc()
        print(f"{'='*60}\n")
        raise HTTPException(status_code=500, detail=error_msg)


@app.get("/api/dados")
async def get_dados():
    """Retorna dados processados em cache"""
    if not cached_data:
        raise HTTPException(status_code=404, detail="Nenhum dado processado. FaÃ§a upload primeiro.")
    
    # Converte DataFrame para dict limpando NaN
    df = cached_data['df']
    dados_dict = df.astype(object).where(pd.notnull(df), None).to_dict('records')
    
    return {
        "resumo": cached_data['resumo'],
        "dados_completos": clean_for_json(dados_dict)
    }


@app.get("/api/regiao/{regiao}")
async def get_dados_regiao(regiao: str):
    """Retorna dados filtrados por regiÃ£o (es, br, int)"""
    if not cached_data:
        raise HTTPException(status_code=404, detail="Nenhum dado processado. FaÃ§a upload primeiro.")
    
    df = cached_data['df']
    
    if 'regiao' not in df.columns:
        raise HTTPException(status_code=400, detail="Dados nÃ£o possuem informaÃ§Ã£o de regiÃ£o")
    
    if regiao not in ['es', 'br', 'int']:
        raise HTTPException(status_code=400, detail="RegiÃ£o invÃ¡lida. Use: es, br, int")
    
    df_regiao = df[df['regiao'] == regiao]
    
    # Recalcula o resumo para esta regiÃ£o
    from copy import deepcopy
    resumo_base = deepcopy(cached_data['resumo'])
    
    # Substitui com dados da regiÃ£o especÃ­fica
    if 'analise_regiao' in resumo_base and regiao in resumo_base['analise_regiao']:
        resumo_regiao = resumo_base['analise_regiao'][regiao]
        # Atualiza campos principais
        resumo_base['total_jogadores'] = resumo_regiao['quantidade']
        resumo_base['percentual_ativos'] = resumo_regiao['percentual_ativos']
        resumo_base['media_saude_login'] = resumo_regiao['score_login_medio']
        resumo_base['media_saude_engajamento'] = resumo_regiao['score_engajamento_medio']
        resumo_base['media_saude_compras'] = resumo_regiao['score_compras_medio']
        resumo_base['media_pontuacao_geral'] = resumo_regiao['score_geral_medio']
        resumo_base['distribuicao_categorias'] = resumo_regiao['distribuicao_categorias']
        resumo_base['regiao_atual'] = regiao
        resumo_base['regiao_nome'] = resumo_regiao['nome']
    
    return {
        "regiao": regiao,
        "nome": get_regiao_nome(regiao),
        "quantidade": len(df_regiao),
        "resumo": resumo_base,
        "jogadores": df_regiao.to_dict('records')
    }


@app.get("/api/vip/{nivel}")
async def get_dados_vip(nivel: int):
    """Retorna dados filtrados por nÃ­vel VIP"""
    if not cached_data:
        raise HTTPException(status_code=404, detail="Nenhum dado processado. FaÃ§a upload primeiro.")
    
    df = cached_data['df']
    
    if 'nivel_vip' not in df.columns:
        raise HTTPException(status_code=400, detail="Dados nÃ£o possuem informaÃ§Ã£o de nÃ­vel VIP")
    
    df_vip = df[df['nivel_vip'] == nivel]
    vip_info = get_vip_info(nivel)
    
    return {
        "nivel": nivel,
        "nome": vip_info['nome'],
        "cor": vip_info['cor'],
        "icone": vip_info['icone'],
        "quantidade": len(df_vip),
        "jogadores": df_vip.to_dict('records')
    }


@app.get("/api/vip")
async def get_resumo_vip():
    """Retorna resumo estatÃ­stico por nÃ­vel VIP"""
    if not cached_data:
        raise HTTPException(status_code=404, detail="Nenhum dado processado. FaÃ§a upload primeiro.")
    
    resumo = cached_data['resumo']
    
    if 'analise_vip' not in resumo:
        raise HTTPException(status_code=400, detail="Dados nÃ£o possuem anÃ¡lise por VIP")
    
    return resumo['analise_vip']


@app.get("/api/export/csv")
async def export_csv():
    """Exporta dados processados como CSV"""
    if not cached_data:
        raise HTTPException(status_code=404, detail="Nenhum dado para exportar")
    
    df = cached_data['df']
    output = io.StringIO()
    df.to_csv(output, index=False, encoding='utf-8-sig')
    output.seek(0)
    
    return StreamingResponse(
        io.BytesIO(output.getvalue().encode('utf-8-sig')),
        media_type="text/csv",
        headers={"Content-Disposition": "attachment; filename=health_score_resultado.csv"}
    )


@app.get("/api/export/excel")
async def export_excel():
    """Exporta dados processados como Excel com parÃ¢metros dinÃ¢micos"""
    if not cached_data:
        raise HTTPException(status_code=404, detail="Nenhum dado para exportar")
    
    df = cached_data['df']
    resumo = cached_data['resumo']
    params = cached_data['params']
    
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        # Aba com dados completos
        df.to_excel(writer, sheet_name='Jogadores', index=False)
        
        # Aba com resumo
        resumo_df = pd.DataFrame([{
            'Data': resumo['data'],
            'Total Jogadores': resumo['total_jogadores'],
            '% Ativos': resumo['percentual_ativos'],
            'MÃ©dia SaÃºde Login': resumo['media_saude_login'],
            'MÃ©dia SaÃºde Engajamento': resumo['media_saude_engajamento'],
            'MÃ©dia SaÃºde Compras': resumo['media_saude_compras'],
            'MÃ©dia PontuaÃ§Ã£o Geral': resumo['media_pontuacao_geral'],
            '% Elite': resumo['distribuicao_categorias'].get('elite', 0),
            '% VIP Ativo': resumo['distribuicao_categorias'].get('vip_ativo', 0),
            '% Bom': resumo['distribuicao_categorias'].get('bom', 0),
            '% EstÃ¡vel': resumo['distribuicao_categorias'].get('estavel', 0),
            '% AtenÃ§Ã£o': resumo['distribuicao_categorias'].get('atencao', 0),
            '% Risco Alto': resumo['distribuicao_categorias'].get('risco_alto', 0),
            '% Risco Queda Receita': resumo['distribuicao_categorias'].get('risco_receita', 0),
            '% Risco Queda Engajamento': resumo['distribuicao_categorias'].get('risco_engajamento', 0),
            '% Churn Iminente': resumo['distribuicao_categorias'].get('churn_iminente', 0),
            '% Oportunidade VIP': resumo['distribuicao_categorias'].get('oportunidade_vip', 0),
            '% Oportunidade': resumo['distribuicao_categorias'].get('oportunidade', 0),
            '% Potencial': resumo['distribuicao_categorias'].get('potencial', 0),
        }])
        resumo_df.to_excel(writer, sheet_name='Resumo', index=False)
        
        # Aba com parÃ¢metros dinÃ¢micos calculados
        params_data = []
        for k, v in params.items():
            if isinstance(v, (int, float)):
                params_data.append({'Parametro': k, 'Valor': round(v, 4)})
            else:
                params_data.append({'Parametro': k, 'Valor': v})
        params_df = pd.DataFrame(params_data)
        params_df.to_excel(writer, sheet_name='Parametros_Dinamicos', index=False)
        
        # Aba com benchmarks comparativos (igual ao Excel)
        benchmarks_data = [
            {'MÃ©trica': 'Torneios', 'MÃ©dia 3d': resumo['estatisticas']['media_torneios_3d'], 
             'Mediana': resumo['estatisticas']['mediana_torneios_3d'],
             'DesvPad': resumo['estatisticas']['desvpad_torneios_3d'], 
             'Por Dia': resumo['benchmarks']['torneios_por_dia']},
            {'MÃ©trica': 'Maratonas', 'MÃ©dia 3d': resumo['estatisticas']['media_maratonas_3d'],
             'Mediana': resumo['estatisticas']['mediana_maratonas_3d'],
             'DesvPad': resumo['estatisticas']['desvpad_maratonas_3d'], 
             'Por Dia': resumo['benchmarks']['maratonas_por_dia']},
            {'MÃ©trica': 'MissÃµes', 'MÃ©dia 3d': resumo['estatisticas']['media_missoes_3d'],
             'Mediana': resumo['estatisticas']['mediana_missoes_3d'],
             'DesvPad': resumo['estatisticas']['desvpad_missoes_3d'], 
             'Por Dia': resumo['benchmarks']['missoes_por_dia']},
            {'MÃ©trica': 'Promos', 'MÃ©dia 3d': resumo['estatisticas']['media_promos_3d'],
             'Mediana': resumo['estatisticas']['mediana_promos_3d'],
             'DesvPad': resumo['estatisticas']['desvpad_promos_3d'], 
             'Por Dia': resumo['benchmarks']['promos_por_dia']},
        ]
        benchmarks_df = pd.DataFrame(benchmarks_data)
        benchmarks_df.to_excel(writer, sheet_name='Benchmarks', index=False)
        
        # Aba com anÃ¡lise por nÃ­vel VIP
        if 'analise_vip' in resumo:
            vip_data = []
            for vip_key, vip_stats in resumo['analise_vip'].items():
                vip_data.append({
                    'NÃ­vel': vip_stats['nivel'],
                    'Nome': vip_stats['nome'],
                    'Quantidade': vip_stats['quantidade'],
                    '% do Total': vip_stats['percentual'],
                    'Score Geral MÃ©dio': vip_stats['score_geral_medio'],
                    'Score Login MÃ©dio': vip_stats['score_login_medio'],
                    'Score Engajamento MÃ©dio': vip_stats['score_engajamento_medio'],
                    'Score Compras MÃ©dio': vip_stats['score_compras_medio'],
                    '% Ativos': vip_stats['percentual_ativos'],
                    '% Elite': vip_stats['distribuicao_categorias'].get('elite', 0),
                    '% VIP Ativo': vip_stats['distribuicao_categorias'].get('vip_ativo', 0),
                    '% Bom': vip_stats['distribuicao_categorias'].get('bom', 0),
                    '% EstÃ¡vel': vip_stats['distribuicao_categorias'].get('estavel', 0),
                    '% AtenÃ§Ã£o': vip_stats['distribuicao_categorias'].get('atencao', 0),
                    '% Risco Alto': vip_stats['distribuicao_categorias'].get('risco_alto', 0),
                    '% Risco Queda Receita': vip_stats['distribuicao_categorias'].get('risco_receita', 0),
                    '% Risco Queda Engajamento': vip_stats['distribuicao_categorias'].get('risco_engajamento', 0),
                    '% Churn Iminente': vip_stats['distribuicao_categorias'].get('churn_iminente', 0),
                    '% Oportunidade VIP': vip_stats['distribuicao_categorias'].get('oportunidade_vip', 0),
                    '% Oportunidade': vip_stats['distribuicao_categorias'].get('oportunidade', 0),
                    '% Potencial': vip_stats['distribuicao_categorias'].get('potencial', 0),
                })
            vip_df = pd.DataFrame(vip_data)
            vip_df.to_excel(writer, sheet_name='Analise_VIP', index=False)
    
    output.seek(0)
    
    return StreamingResponse(
        output,
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        headers={"Content-Disposition": "attachment; filename=health_score_resultado.xlsx"}
    )


# ========== ENDPOINTS DE HISTÃ“RICO ==========

@app.post("/api/historico/salvar")
async def salvar_historico(request: Dict[str, Any]):
    """Salva o estado atual como snapshot do dia e dados individuais dos jogadores"""
    if not cached_data:
        raise HTTPException(status_code=404, detail="Nenhum dado processado. FaÃ§a upload primeiro.")
    
    resumo = cached_data['resumo']
    df = cached_data['df']  # DataFrame completo com dados dos jogadores
    filtros = request.get('filtros', {})
    data_custom = request.get('data')  # Data no formato YYYY-MM-DD
    
    # Usa a data exatamente como recebida do frontend
    if data_custom and isinstance(data_custom, str) and len(data_custom) == 10:
        data_usar = data_custom  # Usa diretamente: YYYY-MM-DD
    else:
        data_usar = datetime.now().strftime("%Y-%m-%d")
    
    print(f"[DEBUG] Data recebida do frontend: {data_custom}")
    print(f"[DEBUG] Data usada para salvar: {data_usar}")
    
    # Salva snapshot geral
    snapshot_id = salvar_snapshot(resumo, filtros, data_usar)
    
    # Salva dados individuais de cada jogador com a mesma data
    try:
        total_salvos = salvar_player_snapshots(df, data_usar)
        print(f"[INFO] {total_salvos} jogadores salvos para acompanhamento individual (data: {data_usar})")
    except Exception as e:
        print(f"[WARN] Erro ao salvar player_snapshots: {e}")
        # NÃ£o falha o snapshot se der erro ao salvar jogadores individuais
    
    return {
        "success": True,
        "message": "Dados do dia salvos com sucesso",
        "snapshot_id": snapshot_id,
        "data": data_usar
    }


@app.delete("/api/historico/{snapshot_id}")
async def deletar_historico(snapshot_id: int):
    """Deleta um snapshot especÃ­fico pelo ID"""
    print(f"[DEBUG] DELETE request recebido - snapshot_id: {snapshot_id}")
    
    try:
        sucesso = deletar_snapshot(snapshot_id=snapshot_id)
        
        if sucesso:
            print(f"[DEBUG] Snapshot {snapshot_id} deletado com sucesso")
            return {
                "success": True,
                "message": f"Snapshot {snapshot_id} deletado com sucesso"
            }
        else:
            print(f"[DEBUG] Snapshot {snapshot_id} nÃ£o encontrado ou erro ao deletar")
            raise HTTPException(status_code=404, detail="Snapshot nÃ£o encontrado")
    except Exception as e:
        print(f"[ERROR] Erro no endpoint delete: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Erro interno: {str(e)}")


@app.delete("/api/historico/data/{data}")
async def deletar_historico_por_data(data: str):
    """Deleta todos os snapshots de uma data especÃ­fica (YYYY-MM-DD)"""
    sucesso = deletar_snapshot(data=data)
    
    if sucesso:
        return {
            "success": True,
            "message": f"Snapshots de {data} deletados com sucesso"
        }
    else:
        raise HTTPException(status_code=404, detail="Nenhum snapshot encontrado para esta data")


@app.get("/api/historico")
async def get_historico(
    regiao: str = Query(None, description="Filtro por regiÃ£o (es, br, int, all)"),
    vip: str = Query(None, description="Filtro por VIP (1-5, all)"),
    dias: int = Query(30, description="NÃºmero de dias no histÃ³rico")
):
    """Retorna histÃ³rico de snapshots com filtros"""
    historico = listar_historico(regiao, vip, dias)
    return {
        "success": True,
        "quantidade": len(historico),
        "historico": historico
    }


@app.get("/api/historico/comparar")
async def comparar_historico(
    inicio: str = Query(..., description="Data inÃ­cio (YYYY-MM-DD)"),
    fim: str = Query(..., description="Data fim (YYYY-MM-DD)")
):
    """Compara dados entre dois perÃ­odos"""
    comparacao = comparar_periodos(inicio, fim)
    return {
        "success": True,
        "comparacao": comparacao
    }


@app.get("/api/historico/executivo")
async def get_resumo_executivo(
    dias: int = Query(7, description="Dias para anÃ¡lise")
):
    """Retorna resumo executivo para apresentaÃ§Ãµes"""
    historico = listar_historico(dias=dias)
    
    if not historico:
        return {
            "success": False,
            "message": "Nenhum histÃ³rico encontrado"
        }
    
    # Ãšltimo dia disponÃ­vel
    ultimo = historico[0]
    
    # Calcular variaÃ§Ãµes se houver histÃ³rico anterior
    variacoes = {}
    if len(historico) > 1:
        anterior = historico[1]
        variacoes = {
            'total_jogadores': round(ultimo['total_jogadores'] - anterior['total_jogadores'], 0),
            'percentual_ativos': round(ultimo['percentual_ativos'] - anterior['percentual_ativos'], 2),
            'score_geral': round(ultimo['media_score_geral'] - anterior['media_score_geral'], 2),
        }
    
    # Totais por cluster (Ãºltimo dia)
    clusters = ultimo['clusters']
    total_jogadores = ultimo['total_jogadores']
    
    return {
        "success": True,
        "data_referencia": ultimo['data'],
        "indicadores_principais": {
            "total_jogadores": ultimo['total_jogadores'],
            "percentual_ativos": ultimo['percentual_ativos'],
            "score_geral_medio": ultimo['media_score_geral'],
            "score_engajamento_medio": ultimo['media_score_engajamento'],
            "score_compras_medio": ultimo['media_score_compras'],
        },
        "variacoes_dia": variacoes,
        "distribuicao_clusters": {
            "Elite": {"qtd": clusters['Elite'], "pct": round(clusters['Elite']/total_jogadores*100, 1) if total_jogadores > 0 else 0},
            "Muito bom": {"qtd": clusters['Muito bom'], "pct": round(clusters['Muito bom']/total_jogadores*100, 1) if total_jogadores > 0 else 0},
            "EstÃ¡vel": {"qtd": clusters['EstÃ¡vel'], "pct": round(clusters['EstÃ¡vel']/total_jogadores*100, 1) if total_jogadores > 0 else 0},
            "Baixo": {"qtd": clusters['Baixo'], "pct": round(clusters['Baixo']/total_jogadores*100, 1) if total_jogadores > 0 else 0},
            "Risco Receita": {"qtd": clusters['Risco: Queda em Receita'], "pct": round(clusters['Risco: Queda em Receita']/total_jogadores*100, 1) if total_jogadores > 0 else 0},
            "Risco Engajamento": {"qtd": clusters['Risco: Queda em Engajamento'], "pct": round(clusters['Risco: Queda em Engajamento']/total_jogadores*100, 1) if total_jogadores > 0 else 0},
        },
        "evolucao": [
            {
                "data": h['data'],
                "total_jogadores": h['total_jogadores'],
                "percentual_ativos": h['percentual_ativos'],
                "score_geral": h['media_score_geral'],
            } for h in historico[:7]  # Ãšltimos 7 dias
        ]
    }


# ========== ENDPOINTS DE ACOMPANHAMENTO INDIVIDUAL ==========

def get_ultimo_registro_todos_jogadores(dias: int = 90) -> List[Dict]:
    """
    Retorna o registro mais recente de TODOS os jogadores que jÃ¡ apareceram no histÃ³rico.
    Mesmo que o jogador nÃ£o tenha dados no dia atual, retorna seu Ãºltimo registro.
    """
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    # Busca o registro mais recente de cada jogador
    cursor.execute('''
        SELECT 
            player_id,
            data,
            score_geral,
            score_engajamento,
            score_compras,
            score_login,
            categoria,
            nivel_vip,
            regiao,
            qtd_compras_7d,
            ticket_medio_7d,
            qtd_torneios_3d,
            qtd_maratonas_3d,
            qtd_missoes_3d,
            qtd_promos_3d,
            qtd_logins_3d
        FROM player_snapshots
        WHERE data >= date('now', '-{} days')
        ORDER BY player_id, data DESC
    '''.format(dias))
    
    rows = cursor.fetchall()
    
    # Agrupa por player_id e pega apenas o mais recente de cada um
    jogadores_unicos = {}
    for row in rows:
        pid = row['player_id']
        if pid not in jogadores_unicos:
            jogadores_unicos[pid] = {
                'player_id': pid,
                'data': row['data'],
                'score_geral': row['score_geral'],
                'score_engajamento': row['score_engajamento'],
                'score_compras': row['score_compras'],
                'score_login': row['score_login'],
                'categoria': row['categoria'],
                'nivel_vip': row['nivel_vip'],
                'regiao': row['regiao'],
                'qtd_compras_7d': row['qtd_compras_7d'],
                'ticket_medio_7d': row['ticket_medio_7d'],
                'qtd_torneios_3d': row['qtd_torneios_3d'],
                'qtd_maratonas_3d': row['qtd_maratonas_3d'],
                'qtd_missoes_3d': row['qtd_missoes_3d'],
                'qtd_promos_3d': row['qtd_promos_3d'],
                'qtd_logins_3d': row['qtd_logins_3d']
            }
    
    conn.close()
    return list(jogadores_unicos.values())


@app.get("/api/players/ultimos")
async def get_players_ultimos(
    dias: int = Query(90, description="Dias para trÃ¡s no histÃ³rico")
):
    """
    Retorna o Ãºltimo registro de todos os jogadores que jÃ¡ apareceram.
    Ãštil para manter a lista completa mesmo quando jogadores estÃ£o ausentes.
    """
    try:
        jogadores = get_ultimo_registro_todos_jogadores(dias)
        
        return {
            "success": True,
            "total": len(jogadores),
            "dias_considerados": dias,
            "jogadores": jogadores
        }
    except Exception as e:
        return {
            "success": False,
            "message": f"Erro ao buscar jogadores: {str(e)}"
        }


@app.get("/api/player/{player_id}/evolucao")
async def get_player_evolucao(
    player_id: str,
    dias: int = Query(30, description="NÃºmero de dias no histÃ³rico")
):
    """
    Retorna a evoluÃ§Ã£o histÃ³rica de um jogador especÃ­fico.
    Permite analisar flutuaÃ§Ã£o entre clusters e impacto de campanhas.
    """
    try:
        evolucao = get_evolucao_player(player_id, dias)
        
        if "error" in evolucao:
            return {
                "success": False,
                "message": evolucao["error"]
            }
        
        return {
            "success": True,
            "player_id": player_id,
            "dias_analisados": dias,
            "evolucao": evolucao
        }
    except Exception as e:
        return {
            "success": False,
            "message": f"Erro ao buscar evoluÃ§Ã£o: {str(e)}"
        }


@app.get("/api/players/flutuacao")
async def get_players_flutuacao(
    cluster_origem: str = Query(None, description="Cluster de origem (ex: 'âš ï¸ AtenÃ§Ã£o')"),
    cluster_destino: str = Query(None, description="Cluster de destino (ex: 'ğŸ“ˆ Bom')"),
    dias: int = Query(7, description="PerÃ­odo de anÃ¡lise em dias"),
    tipo: str = Query("qualquer", description="Tipo: 'melhora', 'piora', 'qualquer'")
):
    """
    Identifica jogadores que mudaram de cluster significativamente.
    Ãštil para medir impacto de campanhas ou detectar churn.
    """
    try:
        players = get_players_com_flutuacao(cluster_origem, cluster_destino, dias, tipo)
        
        return {
            "success": True,
            "total": len(players),
            "filtros": {
                "cluster_origem": cluster_origem,
                "cluster_destino": cluster_destino,
                "dias": dias,
                "tipo": tipo
            },
            "players": players[:50]  # Limita a 50 resultados
        }
    except Exception as e:
        return {
            "success": False,
            "message": f"Erro ao buscar flutuaÃ§Ãµes: {str(e)}"
        }


@app.get("/api/campanhas/analise")
async def analisar_campanhas(
    campanha_nome: str = Query(..., description="Nome da campanha para anÃ¡lise"),
    dias_antes: int = Query(7, description="Dias antes do inÃ­cio da campanha"),
    dias_depois: int = Query(7, description="Dias depois do inÃ­cio da campanha")
):
    """
    Analisa a eficÃ¡cia de uma campanha comparando comportamento antes/depois.
    """
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    try:
        # Busca jogadores que participaram da campanha
        cursor.execute('''
            SELECT player_id, data, score_geral, score_engajamento, score_compras, categoria
            FROM player_snapshots 
            WHERE campanha_nome = ?
            ORDER BY player_id, data ASC
        ''', (campanha_nome,))
        
        rows = cursor.fetchall()
        
        if not rows:
            return {
                "success": False,
                "message": f"Nenhum dado encontrado para a campanha '{campanha_nome}'"
            }
        
        # Agrupa por jogador
        players_data = {}
        for row in rows:
            pid = row['player_id']
            if pid not in players_data:
                players_data[pid] = []
            players_data[pid].append(row)
        
        # Analisa impacto
        analise = {
            "total_participantes": len(players_data),
            "melhoraram": 0,
            "pioraram": 0,
            "mantiveram": 0,
            "variacao_media_geral": 0,
            "variacao_media_compras": 0,
            "variacao_media_engajamento": 0
        }
        
        variacoes_geral = []
        variacoes_compras = []
        variacoes_engajamento = []
        
        for pid, registros in players_data.items():
            if len(registros) < 2:
                continue
            
            primeiro = registros[0]
            ultimo = registros[-1]
            
            var_geral = ultimo['score_geral'] - primeiro['score_geral']
            var_compras = ultimo['score_compras'] - primeiro['score_compras']
            var_engajamento = ultimo['score_engajamento'] - primeiro['score_engajamento']
            
            variacoes_geral.append(var_geral)
            variacoes_compras.append(var_compras)
            variacoes_engajamento.append(var_engajamento)
            
            if var_geral > 5:
                analise["melhoraram"] += 1
            elif var_geral < -5:
                analise["pioraram"] += 1
            else:
                analise["mantiveram"] += 1
        
        if variacoes_geral:
            analise["variacao_media_geral"] = round(sum(variacoes_geral) / len(variacoes_geral), 2)
            analise["variacao_media_compras"] = round(sum(variacoes_compras) / len(variacoes_compras), 2)
            analise["variacao_media_engajamento"] = round(sum(variacoes_engajamento) / len(variacoes_engajamento), 2)
        
        conn.close()
        
        return {
            "success": True,
            "campanha": campanha_nome,
            "analise": analise
        }
        
    except Exception as e:
        conn.close()
        return {
            "success": False,
            "message": f"Erro na anÃ¡lise: {str(e)}"
        }


@app.get("/api/sample")
async def generate_sample():
    """Gera dados de exemplo para teste com distribuiÃ§Ã£o por regiÃ£o"""
    np.random.seed(42)
    n = 100
    
    # DistribuiÃ§Ã£o de traduÃ§Ãµes: 40% BR, 35% ES, 25% INT
    traducoes = (['pt_BR'] * 40) + (['es_AR'] * 15) + (['es_ES'] * 10) + (['es_LA'] * 5) + (['es_MX'] * 5) + (['en_US'] * 10) + (['fr_FR'] * 5) + (['de_DE'] * 5) + (['it_IT'] * 5)
    
    sample_data = pd.DataFrame({
        'player_id': [f'PLAYER_{i:04d}' for i in range(1, n+1)],
        'nivel_vip': np.random.choice([1, 2, 3, 4, 5], n, p=[0.3, 0.3, 0.2, 0.15, 0.05]),
        'lastLogin': [(datetime.now() - timedelta(days=np.random.exponential(5))).strftime('%Y-%m-%d') for _ in range(n)],
        'translation': np.random.choice(traducoes, n),
        'qtd_logins_3d': np.random.poisson(2, n),
        'qtd_compras_7d': np.random.poisson(1, n),
        'qtd_torneios_3d': np.random.poisson(15, n),
        'qtd_maratonas_3d': np.random.poisson(5, n),
        'qtd_missoes_3d': np.random.poisson(8, n),
        'qtd_promos_3d': np.random.poisson(6, n),
        'ticket_medio_7d': np.random.exponential(30, n),
    })
    
    # Processa os dados de exemplo
    df_processado, params = processar_dados_jogadores(sample_data)
    resumo = gerar_resumo_dashboard(df_processado, params)
    
    # Atualiza cache
    cached_data = {
        'df': df_processado,
        'resumo': resumo,
        'params': params,
        'timestamp': datetime.now()
    }
    
    return {
        "success": True,
        "message": "Dados de exemplo gerados com parÃ¢metros dinÃ¢micos",
        "resumo": resumo
    }


if __name__ == "__main__":
    # Porta dinÃ¢mica para deploy (Render, Railway, etc)
    port = int(os.environ.get("PORT", 8080))
    host = os.environ.get("HOST", "127.0.0.1")
    
    print("=" * 60)
    print("  Health Score Dashboard - Iniciando servidor...")
    print("=" * 60)
    print()
    print(f"  Acesse no navegador:")
    print(f"  http://{host}:{port}")
    print()
    print("  Pressione CTRL+C para parar")
    print("=" * 60)
    print()
    uvicorn.run(app, host=host, port=port)
